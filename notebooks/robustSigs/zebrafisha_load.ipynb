{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239ff0a-9d56-4abb-b480-7fd18939dc39",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import scipy\n",
    "import random\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import helpers as h\n",
    "import spontHelpers as sh\n",
    "import matplotlib as mpl\n",
    "import utils as u\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efea16f4-e4db-4f50-acdd-bce564b53b28",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_cvPCA(resp0, maxcols=np.inf):\n",
    "    ss0 = u.shuff_cvPCA(resp0, nshuff=10, maxcols=np.inf)\n",
    "    ss0 = ss0.mean(axis=0)\n",
    "    ss0 = ss0 / ss0.sum()\n",
    "\n",
    "    return ss0\n",
    "\n",
    "def load_xcorr_lags(f0, f1, **kwargs):\n",
    "    xcorr = np.load(f0, **kwargs)\n",
    "    lags =np.load(f1, **kwargs)\n",
    "\n",
    "    return xcorr, lags\n",
    "\n",
    "\n",
    "def compute_cross_corr(sig0, sig1):\n",
    "    xcorr = signal.correlate(sig0, sig1)\n",
    "    lags = signal.correlation_lags(len(sig0), len(sig1))\n",
    "\n",
    "    return xcorr, lags\n",
    "\n",
    "\n",
    "\n",
    "def figure_sanity_checks(d0=None, dlags0=None, dxcorrs=None, idx0=None, nnrois_ids=None, nnrois_corr=None, iter=None):    \n",
    "    mpl.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "    # headers \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    fig0, axs = plt.subplots(nrows=11, ncols=2, figsize=(15, 15), layout='tight', frameon=False)\n",
    "\n",
    "    axs[0, 0].plot(d0[:, idx0][80:1880], label=f'ROI {idx0} : avg correlation with nbrs={0}')\n",
    "    axs[0, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[0, 0].legend()\n",
    "    \n",
    "    \n",
    "    axs[0, 1].plot(d0[:, idx0][80:1880], label=f'ROI {idx0}: avg correlation with nbrs={0}')\n",
    "    axs[0, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[0, 1].legend()\n",
    "    \n",
    "\n",
    "    # Subplots for signals\n",
    "    \n",
    "    axs[1, 0].plot(d0[:, nnrois_ids[0]][80:1880], label=f' Neuron {nnrois_ids[0]} : xcorr \\w ROI av={mean(nnrois_corr[0])}')\n",
    "    axs[1, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[2, 0].plot(d0[:, nnrois_ids[1]][80:1880], label= f\"Neuron {nnrois_ids[1]} : xcorr \\w ROI av={mean(nnrois_corr[1])}\")\n",
    "    axs[2, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[2, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[3, 0].plot(d0[:, nnrois_ids[2]][80:1880], label=f\"Neuron {nnrois_ids[2]} : xcorr \\w ROI av={mean(nnrois_corr[2])}\")\n",
    "    axs[3, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[3, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[4, 0].plot(d0[:, nnrois_ids[3]][80:1880], label=f\"Neuron {nnrois_ids[3]} : xcorr \\w ROI av={mean(nnrois_corr[3])}\")\n",
    "    axs[4, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[4, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[5, 0].plot(d0[:, nnrois_ids[4]][80:1880], label=f\"Neuron {nnrois_ids[4]} : xcorr \\w ROI av={mean(nnrois_corr[4])}\")\n",
    "    axs[5, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[5, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[6, 0].plot(d0[:, nnrois_ids[5]][80:1880], label=f\"Neuron {nnrois_ids[5]}: xcorr \\w ROI av={mean(nnrois_corr[5])}\")\n",
    "    axs[6, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[6, 0].legend()\n",
    "\n",
    "   \n",
    "    axs[7, 0].plot(d0[:, nnrois_ids[6]][80:1880], label=f\"Neuron {nnrois_ids[6]} : xcorr \\w ROI av={mean(nnrois_corr[6])}\")\n",
    "    axs[7, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[7, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[8, 0].plot(d0[:, nnrois_ids[7]][80:1880], label=f\"Neuron {nnrois_ids[7]} : xcorr \\w ROI av={mean(nnrois_corr[7])}\")\n",
    "    axs[8, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[8, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[9, 0].plot(d0[:, nnrois_ids[8]][80:1880], label=f\"Neuron {nnrois_ids[8]} : xcorr \\w ROI av={mean(nnrois_corr[8])}\")\n",
    "    axs[9, 0].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[9, 0].legend()\n",
    "\n",
    "    \n",
    "    axs[10, 0].plot(d0[:, nnrois_ids[9]][80:1880], label=f\"Neuron {nnrois_ids[9]} : xcorr \\w ROI av={mean(nnrois_corr[9])}\")\n",
    "    axs[10, 0].set_xlabel('Signal')\n",
    "    axs[10, 0].set_ylabel('AU')\n",
    "    axs[10, 0].legend()\n",
    "\n",
    "\n",
    "    # subplots for lags and xcorrs\n",
    "    axs[1, 1].plot(dlags0[0], dxcorrs[0], label='X - Correlation with ROI')\n",
    "    axs[1, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    \n",
    "    axs[2, 1].plot(dlags0[1], dxcorrs[1], label='X - Correlation with ROI')\n",
    "    axs[2, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[2, 1].legend()\n",
    "\n",
    "    \n",
    "    axs[3, 1].plot(dlags0[2], dxcorrs[2], label='X - Correlation with ROI')\n",
    "    axs[3, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[3, 1].legend()\n",
    "\n",
    "    axs[4, 1].plot(dlags0[3], dxcorrs[3], label='X - Correlation with ROI')\n",
    "    axs[4, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[4, 1].legend()\n",
    "\n",
    "    axs[5, 1].plot(dlags0[4], dxcorrs[4], label='X - Correlation with ROI')\n",
    "    axs[5, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[5, 1].legend()\n",
    "\n",
    "\n",
    "    axs[6, 1].plot(dlags0[5], dxcorrs[5], label='X - Correlation with ROI')\n",
    "    axs[6, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[6, 1].legend()\n",
    "\n",
    "    \n",
    "    axs[7, 1].plot(dlags0[6], dxcorrs[6], label='X - Correlation with ROI')\n",
    "    axs[7, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[7, 1].legend()\n",
    "\n",
    "\n",
    "    axs[8, 1].plot(dlags0[7], dxcorrs[7], label='X - Correlation with ROI')\n",
    "    axs[8, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[8, 1].legend()\n",
    "\n",
    "    axs[9, 1].plot(dlags0[8], dxcorrs[8], label='X - Correlation with ROI')\n",
    "    axs[9, 1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "    axs[9, 1].legend()\n",
    "    \n",
    "    \n",
    "    axs[10, 1].plot(dlags0[9], dxcorrs[9], label='X - Correlation with ROI')\n",
    "    axs[10, 1].set_xlabel(\"Lags\")\n",
    "    axs[10, 1].set_ylabel(\"X - Correlation\")\n",
    "    axs[10, 1].legend()\n",
    "\n",
    "    fig0.suptitle('Signal          SANITY CHECKS             Correlations and Lags');\n",
    "    plt.savefig(f\"sanity_check_cross_correlation_plots_{idx0}_{iter}.png\");\n",
    "    plt.close();\n",
    "\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ab0f1-cd17-4f42-8db7-7763cfebccee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dp0='/Users/duuta/ppp/data/zebf00/TimeSeries.h5'\n",
    "dp1='/Users/duuta/ppp/data/zebf00/data_full.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee643d5-7566-4a2c-abcf-89b1dd60e255",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = loadmat(dp1, simplify_cells=True)\n",
    "dholder = h5py.File(dp0, 'r')\n",
    "d0 = dholder['CellResp'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df8d75-70ee-4968-a92b-6ae334aed13b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y, z = d1['data']['CellXYZ'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8bfc8-d427-4a95-bc3f-9cfb13ccad13",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d00 = sh.ssplit(d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879718b-993e-40cb-bf8f-e396467619d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d01 = d00[:, :, :10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea4202-e2fd-4fd8-81a3-90f97c52c415",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss0 =compute_cvPCA(d00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336fe0fe-84fe-4c26-9cd9-0247f44b6603",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d071d-8918-4109-8c40-4eef4c9ef77a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss01 = compute_cvPCA(d01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774e638-75ba-4e4b-a6a7-d4f5289bead2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, _, _= u.get_powerlaw(ss0, np.arange(11, 500).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e28a70-9e4e-4ca3-9b64-a4b3029f1b7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1, _, _ = u.get_powerlaw(ss01, np.arange(11, 500).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nums = list(range(50))\n",
    "ID= 1408\n",
    "sig0 = d0[:, ID]\n",
    "for i in range(5):\n",
    "    _lags = {}\n",
    "    _ccorr = {}\n",
    "    for id in nums[i*10: i*10 +10]: \n",
    "        id0 = id % 10\n",
    "        sig1 = d0[:, id]\n",
    "        ccorr = signal.correlate(sig0, sig1)\n",
    "        lags = signal.correlation_lags(len(sig0), len(sig1))\n",
    "        _lags[id0] =lags\n",
    "        _ccorr[id0] = ccorr\n",
    "    nnrois_ids = list(_ccorr.keys())\n",
    "    nnrois_corr = _ccorr\n",
    "    figure_sanity_checks(d0=d0, dlags0=_lags, dxcorrs=_ccorr, idx0=ID, nnrois_corr=nnrois_corr, nnrois_ids=nnrois_ids, iter=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_lags[3][np.argmax(_ccorr[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def smooth_foobar(foobar, positions, nn_list):\n",
    "    # define near\n",
    "    smooth_version = 0*foobar \n",
    "    for idx, val in enumerate(foobar):\n",
    "        x0 = mean(foobar[nn_list[idx]]) \n",
    "        smooth_version[idx] = x0\n",
    "\n",
    "    return smooth_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn= np.array([1, 2, 3, 4])\n",
    "rn= np.array([2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.sum()/rn.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.mean()/rn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "def get_tag_paths(zebfolderpath):\n",
    "    tag = zebfolderpath.split(\"/\")[8]\n",
    "\n",
    "    files = os.listdir(zebfolderpath)\n",
    "    files.sort()\n",
    "    files.remove(\"README_LICENSE.rtf\")\n",
    "\n",
    "    path0, path1 = [zebfolderpath + \"/\" + fname for fname in files]\n",
    "\n",
    "    return tag, path0, path1\n",
    "\n",
    "\n",
    "def read_data(path0, path1, num_rois, scells=True):\n",
    "    dholder = h5py.File(path0, \"r\")\n",
    "    d0 = dholder[\"CellResp\"][:]  # responses\n",
    "    d1 = loadmat(path1, simplify_cells=scells)\n",
    "\n",
    "    eliminated_rois = d1[\"data\"][\"IX_inval_anat\"]\n",
    "    all_rois = d1[\"data\"][\"CellXYZ\"]\n",
    "\n",
    "    used_rois_coor = np.array(\n",
    "        [row for j, row in enumerate(all_rois) if j not in list(eliminated_rois)]\n",
    "    )\n",
    "\n",
    "    x, y, z = used_rois_coor[:num_rois, :].T\n",
    "\n",
    "    return x, y, z, d0\n",
    "\n",
    "\n",
    "def find_nearest_nbrs(ds, roi_idx, n=10):\n",
    "    nn_idx = ds[roi_idx,].argsort()[1 : n + 1]\n",
    "\n",
    "    return nn_idx\n",
    "\n",
    "\n",
    "def compute_distance_matrix(x, y):\n",
    "    ds = squareform(pdist(np.array([x, y]).T, metric=\"euclidean\"))\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def pick_random_nbrs(roi_idx, len0=100, n=10):\n",
    "    all_idx = list(range(len0))\n",
    "    all_idx.remove(roi_idx)\n",
    "    rn_idx = random.sample(all_idx, n)\n",
    "\n",
    "    return rn_idx\n",
    "\n",
    "\n",
    "def reject_outliers(data, m=2):\n",
    "    X = data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def compute_render_ratio_corr(\n",
    "    x, y, d0, dS, num_rois=30000, nnpop=10, rnpop=10, seed=None, tag=None, sdir=None\n",
    "):\n",
    "    nnidx_dict = {}\n",
    "    rnidx_dict = {}\n",
    "    nncorr_dict = {}\n",
    "    rncorr_dict = {}\n",
    "    collect_nn_min_max = []\n",
    "    collect_rn_min_max = []\n",
    "\n",
    "    for roi_idx in range(\n",
    "        num_rois\n",
    "    ):  # need to account for cases where the pass a list of roi indices\n",
    "        random.seed(seed)\n",
    "        roi = d0[:, roi_idx]\n",
    "        nn_idx = find_nearest_nbrs(dS, roi_idx, n=nnpop)\n",
    "        nn_roi = d0[:, nn_idx]\n",
    "        rn_idx = pick_random_nbrs(roi_idx, len0=num_rois, n=rnpop)\n",
    "        rn_roi = d0[:, rn_idx]\n",
    "        nrcorr = []\n",
    "        rncorr = []\n",
    "\n",
    "        for j in range(nn_roi.shape[1]):\n",
    "            nn_corr = np.corrcoef(roi, nn_roi[:, j])[0, 1]\n",
    "            rn_corr = np.corrcoef(roi, rn_roi[:, j])[0, 1]\n",
    "            nrcorr.append(nn_corr)\n",
    "            rncorr.append(rn_corr)\n",
    "            collect_nn_min_max.append(nn_corr)\n",
    "            collect_rn_min_max.append(rn_corr)\n",
    "\n",
    "        nnidx_dict[roi_idx] = nn_idx\n",
    "        rnidx_dict[roi_idx] = rn_idx\n",
    "        nncorr_dict[roi_idx] = nrcorr  # groups of near correlations\n",
    "        rncorr_dict[roi_idx] = rncorr  # groups of random correlations\n",
    "\n",
    "    # srnr_arr = np.array(collect_nn_min_max) / np.array(collect_rn_min_max)\n",
    "    # sPRN = round(np.percentile(srnr_arr, 90), 3)\n",
    "    # filtered0 = [a for a in srnr_arr if a > 0 and a <= sPRN]\n",
    "\n",
    "    # outliers for reasonable distribution\n",
    "    # filtered1 = reject_outliers(srnr_arr)\n",
    "    # mid = np.median(filtered0)\n",
    "    # print('mid', mid)\n",
    "    # vmin = min(filtered0)\n",
    "    # print('vmin', vmin)\n",
    "    # vmax = max(filtered0)\n",
    "    # print('vmax', vmax)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    custom_norm = TwoSlopeNorm(vcenter=1, vmin=0.001, vmax=9)\n",
    "    ax = plt.axes()\n",
    "\n",
    "    for roi_idx in range(\n",
    "        num_rois\n",
    "    ):  # need to take care of cases where num_rois is of indexes\n",
    "        plt.scatter(\n",
    "            x[nnidx_dict[roi_idx]],\n",
    "            y[nnidx_dict[roi_idx]],\n",
    "            marker=\".\",\n",
    "            norm=custom_norm,\n",
    "            cmap=\"rainbow\",\n",
    "            s=0.5,\n",
    "            c=[\n",
    "                np.array(nncorr_dict[roi_idx]).sum()\n",
    "                / np.array(rncorr_dict[roi_idx]).sum()\n",
    "            ]\n",
    "            * len(nnidx_dict[roi_idx]) \n",
    "        )\n",
    "\n",
    "    plt.colorbar(shrink=0.5)\n",
    "    plt.xlabel(\"ROI X Positions\", fontsize=20)\n",
    "    plt.ylabel(\"ROI Y Positions\", fontsize=20)\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.title(\n",
    "        f\"{tag}:Raw correlation ratios of near ROIs:{nnpop} to random ROIs:{rnpop} seed:{seed}\",\n",
    "        fontsize=20,\n",
    "    )\n",
    "    ax.set_facecolor(\"black\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\n",
    "        f\"{sdir}testing_Rawratiocorrelations_{tag}_ROIs:{num_rois}_NN:{nnpop}_seed:{seed}_RN:{rnpop}.png\",\n",
    "    )\n",
    "    plt.close()\n",
    "    # need to run this for different vmax, vmin, mid=1 (first make a function initerim a class later)\n",
    "\n",
    "\n",
    "def main():\n",
    "    num_rois = 2000\n",
    "    seed = None\n",
    "    nnpop = 10\n",
    "    sdir = \"/camp/home/duuta/working/duuta/jobs/plots/ratioCorr/\"\n",
    "\n",
    "    for rnpop in [10, 100, 1000]:\n",
    "        for fpath in glob(\"/camp/home/duuta/working/duuta/ppp0/data/zebf*\")[:1]:\n",
    "            print(f\"reading {fpath}..........\")\n",
    "\n",
    "            # get tag and paths\n",
    "            tag, path0, path1 = get_tag_paths(fpath)\n",
    "\n",
    "            # read file paths\n",
    "            x, y, _, d0 = read_data(path0, path1, num_rois=num_rois, scells=True)\n",
    "            print(\"can read the file path... yes.... frantically reading files.....\")\n",
    "\n",
    "            # compute distances between rois\n",
    "            dS = compute_distance_matrix(x, y)\n",
    "\n",
    "            print(\"franticall computing distances......\")\n",
    "\n",
    "            # compute correlation ratio and render plot\n",
    "            compute_render_ratio_corr(\n",
    "                x,\n",
    "                y,\n",
    "                d0=d0,\n",
    "                dS=dS,\n",
    "                num_rois=num_rois,\n",
    "                nnpop=nnpop,\n",
    "                rnpop=rnpop,\n",
    "                seed=seed,\n",
    "                tag=tag,\n",
    "                sdir=sdir,\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    print(f\"{time.time() - start_time} ----all done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (ipykernel)",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "name": "zebrafisha_load.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
